{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iR6jxysxphoR",
    "outputId": "66bd2387-36cd-4c1f-d7e5-25759d4f93f6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kA64lrsSQZEO",
    "outputId": "cb164cdf-2704-4178-c2a3-e3c3deb482bc"
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "#scipy\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, log_loss, recall_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#other learners\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "#imblearn\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "#webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "#time series\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "import itertools\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "#warning ignorer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "8C5a7LULQZEx",
    "outputId": "6d4c6e7a-78ea-4723-8cd1-295a45325b97"
   },
   "outputs": [],
   "source": [
    "# Reading in pre-processed and transformed data \n",
    "file = '/content/drive/MyDrive/Trial/data/Accidents/Visualized_and_manipulated.csv'\n",
    "df = pd.read_csv(file, low_memory = False)\n",
    "# Dropping unnamed column\n",
    "df.drop(df.columns[0],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "GNsH9mqfQZE2",
    "outputId": "71575bab-ace9-44ef-d48c-e6f38ed827c0"
   },
   "outputs": [],
   "source": [
    "#made separate dataframe w. set index that wouldnt effect data vis above\n",
    "df1=df\n",
    "#set index to accident_index\n",
    "df1.set_index('Accident_Index', inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbgSizheQZE3",
    "outputId": "76ddc2ea-98ab-4e40-9de9-cfcd3bd9b4cb"
   },
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSkQN4ujQZE3",
    "outputId": "55198f78-b8f3-4b30-89d6-07ed314235ae"
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6l_LHPVIQZE4"
   },
   "outputs": [],
   "source": [
    "#create a new target variable - Reduced target class from a multi-class classification to a binary classification \n",
    "# problem to handle the imbalanced dataset and simplify analysis\n",
    " \n",
    "\n",
    "df1.loc[df1.Accident_Severity !='Slight', 'Target_Severe_Indicator'] = 1\n",
    "df1.loc[df1.Accident_Severity =='Slight', 'Target_Severe_Indicator'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LikUuWYQZE4",
    "outputId": "ca331972-3991-45c9-a47a-1eb371cf8dca"
   },
   "outputs": [],
   "source": [
    "df1[\"Target_Severe_Indicator\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Va7iHSxtQZE5",
    "outputId": "8906ee99-0551-4c47-92e3-8dcddd90fe5c"
   },
   "outputs": [],
   "source": [
    "df1[\"Accident_Severity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "ZoGrx8QsQZE5",
    "outputId": "67eb3687-2df8-4c1c-f28d-e6c03282050c"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vqmi3cP3QZE5",
    "outputId": "41dd5793-09d4-4cbb-90e9-bb92069e0b32"
   },
   "outputs": [],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting 'Object' to 'category' dtype - Saves memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dc6INUkTQZE6"
   },
   "outputs": [],
   "source": [
    "for col in set(df1.columns) - set(df1.describe().columns):\n",
    "    df1[col] = df1[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOHdf5AAQZE6",
    "outputId": "e4830292-3919-4cfe-e613-03178eb98f3a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling - removed rows at random to speed up model run times (for testing purposes only) \n",
    "Considering the imbalance of classes in the target variable, it may be worth using random stratified sampling to maintain proportionality of classes of the original dataset (Stratified sampling not carried out here however)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoXKRY6VQZE7"
   },
   "outputs": [],
   "source": [
    "np.random.seed(150)\n",
    "\n",
    "remove_n = 85342 #Sample size to remove from original dataset\n",
    "df = df1\n",
    "drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "df_subset = df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "dkOp_ZkuQZE7",
    "outputId": "7dc58f1a-b075-4a22-dcdf-6b218aae2df6"
   },
   "outputs": [],
   "source": [
    "df_subset.shape\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8o5qjUXQZE7",
    "outputId": "1f9464c4-c684-4ace-c6f0-4a440f64b6de"
   },
   "outputs": [],
   "source": [
    "# 85% to 15% distribution of target class - Proportionality of the original dataset is still maintained\n",
    "df_subset['Target_Severe_Indicator'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting target variable from predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoEmp8e3QZE7"
   },
   "outputs": [],
   "source": [
    "df_X = df_subset.drop('Target_Severe_Indicator', axis=1)  \n",
    "df_Y = df_subset['Target_Severe_Indicator']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tt3osOEbQZE8"
   },
   "outputs": [],
   "source": [
    "# Converting independent categorical features to Numerical by creating Dummy variables\n",
    "\n",
    "df_X_dummy = pd.get_dummies(df_X)\n",
    "#print(dataset_X_dummy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1o5dlpfSQZE8",
    "outputId": "cf55a74e-51a7-4c64-b3d0-7cc5b7e70ebd"
   },
   "outputs": [],
   "source": [
    "df_X_dummy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Applying VarianceThreshold filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1bhUcvgQZFA"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# threshold set to 87% for variance \n",
    "# i.e. if 87% of the column data is the same (i.e. low variation), the column will not be as useful\n",
    "# in the prediction\n",
    "thresh=(.85 * (1 - .85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcueRp_8QZFA"
   },
   "outputs": [],
   "source": [
    "# Wrapper function to identify low variance features and remove them from the dataframe \n",
    "\n",
    "def get_low_variance_columns(dframe=None, columns=None,\n",
    "                             skip_columns=None, thresh=0.0,\n",
    "                             autoremove=False):\n",
    "    try:\n",
    "        # get list of all the original df columns\n",
    "        all_columns = dframe.columns\n",
    "\n",
    "        # remove `skip_columns`\n",
    "        remaining_columns = all_columns.drop(skip_columns)\n",
    "\n",
    "        # get length of new index\n",
    "        max_index = len(remaining_columns) - 1\n",
    "\n",
    "        # get indices for `skip_columns`\n",
    "        skipped_idx = [all_columns.get_loc(column)\n",
    "                       for column\n",
    "                       in skip_columns]\n",
    "\n",
    "        # adjust insert location by the number of columns removed\n",
    "        # (for non-zero insertion locations) to keep relative\n",
    "        # locations intact\n",
    "        for idx, item in enumerate(skipped_idx):\n",
    "            if item > max_index:\n",
    "                diff = item - max_index\n",
    "                skipped_idx[idx] -= diff\n",
    "            if item == max_index:\n",
    "                diff = item - len(skip_columns)\n",
    "                skipped_idx[idx] -= diff\n",
    "            if idx == 0:\n",
    "                skipped_idx[idx] = item\n",
    "\n",
    "        # get values of `skip_columns`\n",
    "        skipped_values = dframe.iloc[:, skipped_idx].values\n",
    "\n",
    "        # get dataframe values\n",
    "        X = dframe.loc[:, remaining_columns].values\n",
    "\n",
    "        # instantiate VarianceThreshold object\n",
    "        vt = VarianceThreshold(threshold=thresh)\n",
    "\n",
    "        # fit vt to data\n",
    "        vt.fit(X)\n",
    "\n",
    "        # get the indices of the features that are being kept\n",
    "        feature_indices = vt.get_support(indices=True)\n",
    "\n",
    "        # remove low-variance columns from index\n",
    "        feature_names = [remaining_columns[idx]\n",
    "                         for idx, _\n",
    "                         in enumerate(remaining_columns)\n",
    "                         if idx\n",
    "                         in feature_indices]\n",
    "\n",
    "        # get the columns to be removed\n",
    "        removed_features = list(np.setdiff1d(remaining_columns,\n",
    "                                             feature_names))\n",
    "        print(\"Found {0} low-variance columns.\"\n",
    "              .format(len(removed_features)))\n",
    "\n",
    "        # remove the columns\n",
    "        if autoremove:\n",
    "            print(\"Removing low-variance features.\")\n",
    "            # remove the low-variance columns\n",
    "            X_removed = vt.transform(X)\n",
    "\n",
    "            print(\"Reassembling the dataframe (with low-variance \"\n",
    "                  \"features removed).\")\n",
    "            # re-assemble the dataframe\n",
    "            dframe = pd.DataFrame(data=X_removed,\n",
    "                                  columns=feature_names)\n",
    "\n",
    "            # add back the `skip_columns`\n",
    "            for idx, index in enumerate(skipped_idx):\n",
    "                dframe.insert(loc=index,\n",
    "                              column=skip_columns[idx],\n",
    "                              value=skipped_values[:, idx])\n",
    "            print(\"Succesfully removed low-variance columns.\")\n",
    "\n",
    "        # do not remove columns\n",
    "        else:\n",
    "            print(\"No changes have been made to the dataframe.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Could not remove low-variance features. Something \"\n",
    "              \"went wrong.\")\n",
    "        pass\n",
    "\n",
    "    return dframe, removed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJqAdkQaQZFA",
    "outputId": "4302759c-c71e-4a88-e001-a0fbd9c17e28"
   },
   "outputs": [],
   "source": [
    "# retrieve new dataframe (with low variance features)\n",
    "df_X_new, low_var_col = get_low_variance_columns(df_X_dummy,[],[],thresh, True) \n",
    "#Set to True to remove low variance columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Re84g_5AQZFA",
    "outputId": "573be2e1-94ed-4036-eae0-6f8e70275523"
   },
   "outputs": [],
   "source": [
    "df_X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "HOVCZL09QZFB",
    "outputId": "a04cabe4-9009-4575-f4e8-dbd69f40d8cb"
   },
   "outputs": [],
   "source": [
    "df_X_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Normalizing data** - adjusting values measured on different scales to a notionally common scale (between 0 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U33TiT-WQZFS"
   },
   "outputs": [],
   "source": [
    "df_X_normalized=(df_X_new-df_X_new.min())/(df_X_new.max()-df_X_new.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "cAOyz3RDQZFT",
    "outputId": "362cf666-5830-476c-849d-421ed427e5f6"
   },
   "outputs": [],
   "source": [
    "df_X_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwBU9FlVQZFV"
   },
   "outputs": [],
   "source": [
    "df_X=df_X_normalized.round(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "FZaYqUwAQZFV",
    "outputId": "dbf05dfc-5fdc-4294-c1a2-bb2958b99a2a"
   },
   "outputs": [],
   "source": [
    "df_X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nClxiJdWQZFV",
    "outputId": "8657d9d9-e73c-437e-dfe3-26bc8c9bcd27"
   },
   "outputs": [],
   "source": [
    "df_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsZsG_lfkOHP"
   },
   "outputs": [],
   "source": [
    "# 80 train -20 test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with classifier machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJCL4bNyI3iS"
   },
   "outputs": [],
   "source": [
    "#confusion matrix plot function\n",
    "def cm_plot(var):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.style.use('dark_background')\n",
    "    plt.clf()\n",
    "    plt.imshow(var, interpolation='nearest', cmap='tab20')\n",
    "    classNames = ['No Loyalty','Loyalty']\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual\\n')\n",
    "    plt.xlabel('Predicted\\n')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\"=\"+str(var[i][j]),horizontalalignment='center', \n",
    "                     color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqQvC_kR8pMJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLJ3HVdO74hT"
   },
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZA5CdLvPM_gE",
    "outputId": "5a7b5448-f858-4c58-9149-d9d087ca23b5"
   },
   "outputs": [],
   "source": [
    "#Try modeling using  different classification models\n",
    "classifiers = [\n",
    "               BalancedBaggingClassifier(max_features=df_X.shape[1], n_estimators=500, replacement=True,\n",
    "                              sampling_strategy='majority', random_state=42),\n",
    "               GaussianNB(),\n",
    "               SVC(kernel='linear',\n",
    "                   class_weight='balanced', # penalize\n",
    "                   probability=True)]                    \n",
    "#putting results in df\n",
    "res_cols=[\"Classifier\", \"Accuracy\",\"precision\", \"Recall\", \"Roc Auc\",]\n",
    "results = pd.DataFrame(columns=res_cols)\n",
    "\n",
    "for clf_0 in classifiers:\n",
    "    clf_0.fit(X_train,y_train)\n",
    "    name = clf_0.__class__.__name__\n",
    "    \n",
    "    print(\"\\n\"*3)\n",
    "    print(name,\"Results:\")\n",
    "       \n",
    "    print('~'*40)\n",
    "    y_pred = clf_0.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    cv= np.mean(cross_val_score(clf_0, X_train, y_train, cv=3))\n",
    "    print(\"Cross validation scores:\",cv)\n",
    "    \n",
    "    \n",
    "    train_predictions = clf_0.predict_proba(X_test)\n",
    "    logloss = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(logloss))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    cm_plot(cm)\n",
    "    \n",
    "    #FPR and Error Rate setup\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    fpr = fp/(tn+fp)\n",
    "    ers = 1-acc\n",
    "    rec= recall_score(y_test, y_pred)\n",
    "    roc=roc_auc_score(y_test, y_pred)\n",
    "    precision= precision_score(y_test, y_pred)\n",
    "    f1s=f1_score(y_test, y_pred)\n",
    "    results_final = pd.DataFrame([[name, round(acc*100,3),round(precision*100,3), round(rec*100,3), round(roc*100,3),]],\n",
    "                                 columns=res_cols)\n",
    "    results = results.append(results_final)   \n",
    "print(\"*\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOAIADDgZxyr"
   },
   "source": [
    "### Penalize Algorithms (Cost-Sensitive Training) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RS6oXKrAb74l"
   },
   "source": [
    "During training, we can use the argument class_weight='balanced'  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "\n",
    "We also want to include the argument probability=True  if we want to enable probability estimates for SVM algorithms.\n",
    "\n",
    "Let's train a model using Penalized-SVM on the original imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "-67Adr76ZsUu",
    "outputId": "135743f0-8355-48c9-9911-803bd3dca241"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Train model\n",
    "clf_2 = SVC(kernel='linear',\n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True)\n",
    "clf_2.fit(X_train, y_train)\n",
    "#putting results in df\n",
    "res_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\",\"precision\", \"Cross Val\", \"Recall\", \"Roc Auc\",\"F1\", \n",
    "          \"False Positive Rate\", \"Error Rate\"]\n",
    "results = pd.DataFrame(columns=res_cols)\n",
    "print(\"\\n\"*3)      \n",
    "print('~'*40)\n",
    "pred_y_2 = clf_2.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred_y_2)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "cv= np.mean(cross_val_score(clf_2, X_train, y_train, cv=3))\n",
    "print(\"Cross validation scores:\",cv)\n",
    "    \n",
    "    \n",
    "train_predictions = clf_2.predict_proba(X_test)\n",
    "logloss = log_loss(y_test, train_predictions)\n",
    "print(\"Log Loss: {}\".format(logloss))\n",
    "    \n",
    "cm = confusion_matrix(y_test, pred_y_2)\n",
    "    \n",
    "cm_plot(cm)\n",
    "    \n",
    "#FPR and Error Rate setup\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_y_2).ravel()\n",
    "    \n",
    "fpr = fp/(tn+fp)\n",
    "ers = 1-acc\n",
    "rec= recall_score(y_test, pred_y_2)\n",
    "prob_y_2 = clf_2.predict_proba(X_test)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y_test, prob_y_2) )\n",
    "roc=roc_auc_score(y_test, prob_y_2)\n",
    "prec= precision_score(y_test, pred_y_2)\n",
    "f1s=f1_score(y_test,pred_y_2)\n",
    "print(\"*\"*40)\n",
    "results_final10 = pd.DataFrame([[name, round(acc*100,3), round(logloss,3), \n",
    "                                   round(cv*100,3), round(prec*100,3),round(rec*100,3), round(roc*100,3),\n",
    "                                   round(f1s*100,3),round(fpr*100,3),round(ers*100,3)]],\n",
    "                                 columns=res_cols)\n",
    "results10 = results.append(results_final10)\n",
    "print(\"Results Shape\",results10.shape)\n",
    "results10.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "YAbq9uN9ORSd",
    "outputId": "317cf999-10d4-43b2-fdcf-96eef7d91b53"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "prob_y_13 = clf_2.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "prob_y_13 = [p[1] for p in prob_y_13]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, prob_y_13)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_y_13)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOhU1GKjkqH8"
   },
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "tVWTE44AurhW",
    "outputId": "423fa753-fb6f-4966-f4c5-c4f56dba7cff"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_4 = GaussianNB()\n",
    "clf_4.fit(X_train,y_train)\n",
    "#putting results in df\n",
    "res_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\",\"precision\", \"Cross Val\", \"Recall\", \"Roc Auc\",\"F1\", \n",
    "          \"False Positive Rate\", \"Error Rate\"]\n",
    "results = pd.DataFrame(columns=res_cols)\n",
    "print(\"\\n\"*3)      \n",
    "print('~'*40)\n",
    "pred_y_4 = clf_4.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred_y_4)\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "cv= np.mean(cross_val_score(clf_4,X_train,y_train, cv=3))\n",
    "print(\"Cross validation scores:\",cv)\n",
    "    \n",
    "    \n",
    "train_predictions = clf_4.predict_proba(X_test)\n",
    "logloss = log_loss(y_test, train_predictions)\n",
    "print(\"Log Loss: {}\".format(logloss))\n",
    "    \n",
    "cm = confusion_matrix(y_test, pred_y_4)\n",
    "    \n",
    "cm_plot(cm)\n",
    "    \n",
    "#FPR and Error Rate setup\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_y_4).ravel()\n",
    "    \n",
    "fpr = fp/(tn+fp)\n",
    "ers = 1-acc\n",
    "rec= recall_score(y_test, pred_y_4)\n",
    "prob_y_4 = clf_4.predict_proba(X_test)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print( roc_auc_score(y_test, prob_y_4) )\n",
    "roc=roc_auc_score(y_test, prob_y_4)\n",
    "prec= precision_score(y_test, pred_y_4)\n",
    "f1s=f1_score(y_test,pred_y_4)\n",
    "print(\"*\"*40)\n",
    "results_final11 = pd.DataFrame([[name, round(acc*100,3), round(logloss,3), \n",
    "                                   round(cv*100,3), round(prec*100,3),round(rec*100,3), round(roc*100,3),\n",
    "                                   round(f1s*100,3),round(fpr*100,3),round(ers*100,3)]],\n",
    "                                 columns=res_cols)\n",
    "results11 = results.append(results_final11)\n",
    "print(\"Results Shape\",results11.shape)\n",
    "results11.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "ua7VDU0ULdWS",
    "outputId": "613f6399-210d-4fea-c90e-8eb557895fe6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "prob_y_13 = clf_4.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "prob_y_13 = [p[1] for p in prob_y_13]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, prob_y_13)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_y_13)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Balanced Bagging Classifier\n",
    "For the following Balanced algorithms from imblearn we will be using the standard testing and training sets (X_train, X_test, y_train, y_test) and will allow the algorithms to do the resampling.<br> <br>For the sampling_strategy, we will be using majority as the solution.<br><br>'majority': resample only the majority class\n",
    "\n",
    "We will then gather the results of some scoring metrics (Accuracy, Log Loss, Cross Validation, Recall, Roc Auc, F1, False Positive Rate, Error Rate), and put those scores into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "-gkRV3yLOKXu",
    "outputId": "1c9c129c-981d-42c4-d1a8-7ba4ce257f95"
   },
   "outputs": [],
   "source": [
    "clf_5 = BalancedBaggingClassifier(max_features=df_X.shape[1], n_estimators=500, replacement=True,\n",
    "                              sampling_strategy='majority', random_state=42)\n",
    "clf_5.fit(X_train,y_train)\n",
    "#putting results in df\n",
    "res_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\",\"precision\", \"Cross Val\", \"Recall\", \"Roc Auc\",\"F1\", \n",
    "          \"False Positive Rate\", \"Error Rate\"]\n",
    "results = pd.DataFrame(columns=res_cols)\n",
    "print(\"\\n\"*3)      \n",
    "print('~'*40)\n",
    "pred_y_5 = clf_5.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred_y_5 )\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "cv= np.mean(cross_val_score(clf_5,X_train,y_train, cv=3))\n",
    "print(\"Cross validation scores:\",cv)\n",
    "    \n",
    "    \n",
    "train_predictions = clf_5.predict_proba(X_test)\n",
    "logloss = log_loss(y_test, train_predictions)\n",
    "print(\"Log Loss: {}\".format(logloss))\n",
    "    \n",
    "cm = confusion_matrix(y_test, pred_y_5 )\n",
    "    \n",
    "cm_plot(cm)\n",
    "    \n",
    "#FPR and Error Rate setup\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_y_5 ).ravel()\n",
    "    \n",
    "fpr = fp/(tn+fp)\n",
    "ers = 1-acc\n",
    "rec= recall_score(y_test, pred_y_5 )\n",
    "prob_y_5 = clf_4.predict_proba(X_test)\n",
    "prob_y_5 = [p[1] for p in prob_y_5]\n",
    "print( roc_auc_score(y_test, prob_y_5) )\n",
    "roc=roc_auc_score(y_test, prob_y_5)\n",
    "prec= precision_score(y_test, pred_y_5 )\n",
    "f1s=f1_score(y_test,pred_y_5 )\n",
    "print(\"*\"*40)\n",
    "results_final = pd.DataFrame([[name, round(acc*100,3), round(logloss,3), \n",
    "                                   round(cv*100,3), round(prec*100,3),round(rec*100,3), round(roc*100,3),\n",
    "                                   round(f1s*100,3),round(fpr*100,3),round(ers*100,3)]],\n",
    "                                 columns=res_cols)\n",
    "results = results.append(results_final)\n",
    "print(\"Results Shape\",results.shape)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "9hEVTvGaN3-P",
    "outputId": "c79bb6bf-9df4-4792-d45c-27a2b5e7b693"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "prob_y_13 = clf_5.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "prob_y_13 = [p[1] for p in prob_y_13]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, prob_y_13)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_y_13)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7IhWfIiHiCY"
   },
   "source": [
    "# Choice\n",
    "Based on the visualizations above, Balanced Bagging Classifier from imblearn is the algorithm of choice for this data. While some of the scores may have been close, Balanced Bagging Classifier had higher scores in Accuracy, Cross Validation, and Specificity. The algorithm also had the lower Error Rate and False Positive Rates of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "yDyshKUPRggz",
    "outputId": "acf04542-2a2a-41a1-ff7c-a15914bd3702"
   },
   "outputs": [],
   "source": [
    "\n",
    "#start\n",
    "start_res_bbag_w_lgbm = time.time()\n",
    "\n",
    "# Balanced Bagging Classifier\n",
    "res_bbag_w_lgbm = BalancedBaggingClassifier(base_estimator=LGBMClassifier(learning_rate =0.03, \n",
    "                                                                          max_depth=40, \n",
    "                                                                          min_data_in_leaf=10,\n",
    "                                                                          n_estimators=500, \n",
    "                                                                          num_leaves=50, \n",
    "                                                                          random_state = 42), \n",
    "                                            max_features=df_X.shape[1], n_estimators=500, \n",
    "                                            replacement=True,\n",
    "                                            random_state=42)\n",
    "res_bbag_w_lgbm.fit(X_train, y_train)\n",
    "pred_res_bbag_w_lgbm = res_bbag_w_lgbm.predict(X_test)\n",
    "\n",
    "   \n",
    "# Creates a confusion matrix\n",
    "res_bbag_w_lgbm_cm = confusion_matrix(y_test,pred_res_bbag_w_lgbm)\n",
    "\n",
    "# Transform to df for easier plotting\n",
    "res_bbag_w_lgbm_cm_df = pd.DataFrame(res_bbag_w_lgbm_cm,\n",
    "                     index = ['Not Severe','Severe'], \n",
    "                     columns = ['Not Severe','Severe'])\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.style.use('dark_background')\n",
    "sns.heatmap(res_bbag_w_lgbm_cm_df, annot=True, fmt=\"d\", cmap='viridis', linecolor='black', linewidths=1)\n",
    "plt.title('Balanced Bagging with LightGBM Accuracy: {0:.2f}%'.format(accuracy_score(y_test,pred_res_bbag_w_lgbm )*100),\n",
    "          fontsize=15)\n",
    "plt.ylabel('Actual\\n')\n",
    "plt.xlabel('Predicted\\n')\n",
    "plt.show()\n",
    "#print(\"Resampled Balanced Bagging with LightGBM Classifier Cross Validation Score: {:0.2f}%\"\n",
    "#       .format(np.mean(cross_val_score(res_bbag_w_lgbm, X_train, y_train, cv=3)*100)))\n",
    "print('\\n')\n",
    "#end\n",
    "end_res_bbag_w_lgbm = time.time()\n",
    "print(\"\\n Balanced Bagging with LightGBM Time: \",end_res_bbag_w_lgbm - start_res_bbag_w_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQNmQ2CcRxrI",
    "outputId": "743d4950-7997-4066-ae63-2d5a100a7d65"
   },
   "outputs": [],
   "source": [
    "#extracting true_positives, false_positives, true_negatives, false_negatives\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,pred_res_bbag_w_lgbm).ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test,pred_res_bbag_w_lgbm)*100\n",
    "specificity = tn/(tn+fp)*100\n",
    "fpr = fp/(tn+fp)*100\n",
    "ers = 100-accuracy\n",
    "\n",
    "\n",
    "train_predictions2 = res_bbag_w_lgbm.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print(\" Balanced Bagging Classifier with LightGBM Specificity Score: {0:.2f}%\".format(specificity))\n",
    "print(\" Balanced Bagging Classifier with LightGBM False Positive Rate Score: {0:.2f}%\".format(fpr))\n",
    "print(\" Balanced Bagging Classifier with LightGBM Error Rate Score: {0:.2f}%\".format(ers))\n",
    "\n",
    "#Check scores\n",
    "print(\"Balanced Bagging Classifier with LightGBM Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_res_bbag_w_lgbm )*100))\n",
    "print(\"Balanced Bagging Classifier with LightGBM F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_res_bbag_w_lgbm,average=\"macro\")*100))\n",
    "print(\"Balanced Bagging Classifier with LightGBM Precision Scoreres_: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_res_bbag_w_lgbm, average=\"macro\")*100))\n",
    "print(\"Balanced Bagging Classifier with LightGBM Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_res_bbag_w_lgbm, average=\"macro\")*100))\n",
    "print(\"Balanced Bagging Classifier with LightGBM Roc Auc Score: {0:.2f}%\"\n",
    "      .format(roc_auc_score(y_test, pred_res_bbag_w_lgbm)*100))\n",
    "print(\"Balanced Bagging Classifier with LightGBM Log Loss {0:.2f}%\"\n",
    "      .format(log_loss(y_test, train_predictions2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "EQ7YFtfNHpN5",
    "outputId": "5e910527-46bb-43b9-a589-fb056ca15304"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "prob_y_14 = res_bbag_w_lgbm.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "prob_y_14 = [p[1] for p in prob_y_14]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, prob_y_14)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_y_14)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qt964P7E0IYC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Trial Combination  Sure Expected results (1)checkpoint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
